\section{A treap-based associative hash function}
\label{s:treap}

A treap is a randomized balanced binary (search) tree. A treap satisfies two
properties.  First, it is an ordered tree, where the in-order traversal of the
nodes with their values corresponds to the original order of the values in the
tree. Second, it assigns a priority to each node and satisfies the heap
property that each node has a higher priority than its children (breaking ties
by order of values).

Normally each treap node is given a random priority, and that ensures that the
treap is balanced. However, a treap is naturally transformed into a
history-independent data-structure by assigning each node a priority derived
from a pseudo-random function $f$ that maps node values $a_i$ to priorities
$p_i = f(a_i)$. This derandomized treap is history-independent because the two
treap properties combined completely constrain the shape of the tree; in other
words, any two treaps that satisfy both properties must have the same shape. In
our context this is great, as it means the two trees will have the same root
Merkle hash!

To use the treap as an associative hash function, we need to extract a fringe $F_s$
from a treap $T_s$ that still supports efficient merging. To understand what a
fringe $F_s$ should look like, we will consider the algorithm that merges two
trees $T_a$ and $T_b$. Intuitively, the root node of the merged tree $T_{a||b}$
must be either the root node of $T_a$, or the root node of $T_b$, as one of those
must have the highest priority in all of $a||b$. The node to the left of $T_a$'s
root node will keep their structure, as none of their priorities or values will change.
Similarly, the nodes to the right of $T_b$'s root node keep their place. Only
the node in between the root nodes might change. This is handled by the merge function
recursively merging two trees:

\input{code/treap-merge.py}

This treap merge routine is efficient as it only descends into one node. If
the treaps are balanced, merging two treaps take time $O(\log |a| + \log |b|)$.
More importantly, merging two treaps only requires access to a small part of
the original trees. 

To construct a fringe, we will store only the nodes that could be accessed by
the merge algorithm. Luckily, there are not many of those nodes.  When merging
two trees, we only ever access the right child of $a$, and only ever access the
left child of $b$. To support any kind of merging, we only need to store the
nodes on the outside of the tree: Nodes that can be reached either by only
going left, or by only going right from the root of the tree. We call these
nodes the fringe of the tree.  The size of the fringe $F_s$ is
proportional is at most twice the height of the tree, or $O(\log |s|)$ for
sequences $s$ with balanced trees.

%\input{code/treap-extract.py}

%After merging, most nodes in the tree remain the same, and so their hashes
%remain the same. This means we can re-compute the hashes of the changed nodes
%in time $O(\log |a| + \log |b|)$, because the hashes of all the other nodes
%haven't changed.

For some use-cases, the treap is a balanced tree -- namely, if $f$ behaves
randomly for every element. That is the case when the alphabet $\Sigma =
\{0,1\}^k$ is large and no two elements in the sequence have the same value.
That is likely, for example, when hashing sequences of SHA512 values that each
contain a unique timestamp. In other scenarios, the treap might be very
unbalanced.  For example, if $a_1 = a_2 = \ldots = a_n$ the treap will
degenerate into a tree of depth $n$, or a linked-list. This is the problem that
we will address by using SeqHash in \S\ref{s:seqhash}.

\paragraph{An aside: A handwavy argument as to why we need randomness for
history-independent balanced binary trees.} I believe that we need
pseudo-random functions to construct performant balanced binary trees that
support efficient merging. Why? Well, we must somehow pick a node in the tree
to be the root node. Picking the root node according to index is going to be
problematic, as prepending a new value changes all other value's indices.
Picking the root node according to value (say, maximum) is tricky as well, as
values might very well exhibit patterns that lead to an unbalanced tree; for
example, they might be linearly increasing.  Somehow, we need to pick a
``nicely average'' node to be the root, and it seems that the ideal way to
determine that is by appealing to a (pseudo-)random oracle.
